<!doctype html><html lang=en-gb><head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#"><title>Continuous Benchmarks on a Budget | The blog of a software developer and tester.</title>
<meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta property="author" content="Martin Costello"><meta name=copyright content="&copy; Martin Costello 2014-2025"><meta name=description content="Using GitHub Actions, GitHub Pages and Blazor to run and visualise continuous benchmarks with BenchmarkDotNet with zero hosting costs."><meta name=language content="en"><meta name=theme-color content="#ffffff"><meta name=keywords content="actions,benchmarks,benchmarkdotnet,ci,dotnet,github"><meta name=robots content="INDEX"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="article:author" content="10100867762061905"><meta property="article:published_time" content="2024-09-23T00:00:00Z"><meta property="article:modified_time" content="2024-09-23T00:00:00Z"><meta property="article:tag" content="actions,benchmarks,benchmarkdotnet,ci,dotnet,github"><meta property="fb:profile_id" content="10100867762061905"><meta name=application-name content="Martin Costello's Blog"><meta name=msapplication-config content="browserconfig.xml"><meta name=msapplication-navbutton-color content="#0095DA"><meta name=msapplication-starturl content="/"><meta property="og:description" content="Using GitHub Actions, GitHub Pages and Blazor to run and visualise continuous benchmarks with BenchmarkDotNet with zero hosting costs."><meta property="og:image" content="https://cdn.martincostello.com/blog_benchmarks-regression.png"><meta property="og:locale" content="en_GB"><meta property="og:site_name" content="Martin Costello's Blog"><meta property="og:title" content="Continuous Benchmarks on a Budget"><meta property="og:type" content="article"><meta property="og:updated_time" content="2024-09-23T00:00:00Z"><meta property="og:url" content="https://blog.martincostello.com/continuous-benchmarks-on-a-budget/"><meta name=twitter:card content="summary"><meta name=twitter:creator content="@martin_costello"><meta name=twitter:description content="Using GitHub Actions, GitHub Pages and Blazor to run and visualise continuous benchmarks with BenchmarkDotNet with zero hosting costs."><meta name=twitter:domain content="blog.martincostello.com"><meta name=twitter:image content="https://cdn.martincostello.com/blog_benchmarks-regression.png"><meta name=twitter:image:alt content="Martin Costello"><meta name=twitter:site content="@martin_costello"><meta name=twitter:title content="Continuous Benchmarks on a Budget"><meta name=twitter:url content="https://blog.martincostello.com/continuous-benchmarks-on-a-budget/"><meta name=twitter:label1 content="Written by"><meta name=twitter:data1 content="Martin Costello"><meta name=google-site-verification content="ji6SNsPQEbNQmF252sQgQFswh-b6cDnNOa3AHvgo4J0"><meta name=msvalidate.01 content="D6C2E7551C902F1A396D8564C6452930"><link rel=canonical href=https://blog.martincostello.com/continuous-benchmarks-on-a-budget/><link rel=manifest href=/manifest.webmanifest><link href=https://cdn.martincostello.com/favicon.ico rel="shortcut icon" type=image/x-icon><link href=/sitemap.xml rel=sitemap type=application/xml><link href=/feed.xml rel=alternate type=application/rss+xml title=Atom></head><body><nav class="navbar navbar-expand-lg navbar-dark bg-primary"><div class=container><a href=/ class=navbar-brand><span class="fa-solid fa-laptop-code" aria-hidden=true></span>
blog.martincostello.com
</a><button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#site-navbar aria-controls=site-navbar aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=site-navbar><ul class="navbar-nav me-auto"><li class=nav-item><a class=nav-link href=/archive/ title="View the post archive">Archive
<span class="fa-solid fa-box-archive" aria-hidden=true></span></a></li></ul><ul class=navbar-nav><li class=nav-item><a class=nav-link href=/about-me/ title="About Martin">About Me
<span class="fa-solid fa-circle-info" aria-hidden=true></span></a></li></ul></div></div></nav><main class="container body-content"><div class="p-4 mb-3 bg-light rounded-3"><div class="container-fluid py-3"><h1 class=display-5>Continuous Benchmarks on a Budget</h1><p class="col-md-8 fs-4 lead">Using GitHub Actions, GitHub Pages and Blazor to run and visualise continuous benchmarks with BenchmarkDotNet with zero hosting costs.</p></div></div><p><div class="row d-none d-md-block"><div class=col-6>23 September 2024 by <a href=/about-me/ rel=noopener title="About Martin Costello">Martin Costello</a> |
<a href=/feed.xml rel=noopener title="View the RSS syndication feed"><span class="fa-solid fa-rss" aria-hidden=true></span></a></div></div><div class="row d-md-none"><div class=col-12>23 September 2024 by <a href=/about-me/ rel=noopener title="About Martin Costello">Martin Costello</a></div><div class=col-12><a href=/feed.xml rel=noopener title="View the RSS syndication feed"><span class="fa-solid fa-rss" aria-hidden=true></span></a></p></div></div></p><p><div class=row><div class=col-lg-6><a href="https://bsky.app/intent/compose?text=Continuous+Benchmarks+on+a+Budget+by+%40martincostello.com+-+https%3A%2F%2Fblog.martincostello.com%2Fcontinuous-benchmarks-on-a-budget%2F" target=_blank rel=noopener class="btn btn-info btn-sm" title="Share on Bluesky">Share on Bluesky
<span class="fa-brands fa-bluesky" aria-hidden=true></span></a></div></div></p><p><img class="img-fluid mx-auto d-block" src=https://cdn.martincostello.com/blog_benchmarks-regression.png alt="A chart showing a time series for performance and memory usage with an increase in memory usage in the most recent data points" title="A chart showing a time series for performance and memory usage with an increase in memory usage in the most recent data points"></p><p>Over the last few months I&rsquo;ve been doing a bunch of testing with the <a href=https://blog.martincostello.com/whats-new-for-openapi-with-dotnet-9/ title="What's New for OpenAPI with .NET 9">new OpenAPI support in .NET 9</a>.
As part of that testing, I wanted to take a look at how the performance of the new libraries compared to the existing
open source libraries for OpenAPI support in .NET, the most popular including <a href=https://github.com/RicoSuter/NSwag title="The NSwag repository on GitHub">NSwag</a> and <a href=https://github.com/domaindrivendev/Swashbuckle.AspNetCore title="The Swashbuckle.AspNetCore repository on GitHub">Swashbuckle.AspNetCore</a>.</p><p>It&rsquo;s fairly easy to get up and running writing some benchmarks using <a href=https://github.com/dotnet/BenchmarkDotNet title="The BenchmarkDotNet repository on GitHub">BenchmarkDotNet</a>, but it&rsquo;s often a task
that you need to sit down and do manually when you have the need, and then gets forgotten about as time goes on. Because of that,
I thought it would be a fun mini-project to set up some automation to run the benchmarks on a continuous basis so that I could
monitor the performance of my open source projects easily going forwards.</p><p>In this post I&rsquo;ll cover how I went about setting up a continuous benchmarking pipeline using GitHub Actions, <a href=https://pages.github.com/ title="GitHub Pages">GitHub Pages</a>
and <a href=https://learn.microsoft.com/aspnet/core/blazor/ title="ASP.NET Core Blazor">Blazor</a> to run and visualise the results of the benchmarks on a &ldquo;good enough&rdquo; basis without needing to spend any money__*__
on infrastructure.</p><p>READMORE</p><p><em>*Unless you want to use this with GitHub Enterprise Server or non-public repositories. More information about this later.</em></p><h2 id=the-ideal>The Ideal</h2><p>In an ideal world, we&rsquo;d all have access to a dedicated performance lab, with a number of dedicated high-specification physical
machines that we could use to run benchmarks on a regular basis. We could generate reams of data from these benchmarks, and then
ingest that data into a data warehousing solution and run reports, generate dashboards and much more to monitor performance metrics
for the software we&rsquo;re building.</p><p>The .NET team is an engineering team with the budget for such a setup, and they have engineers dedicated to performance testing
and the supporting infrastructure needed to run them. For example they have a <a href=https://aka.ms/aspnet/benchmarks title="ASP.NET Core Benchmarks Power BI Dashboard">dashboard</a> using
<a href=https://learn.microsoft.com/power-bi/fundamentals/power-bi-overview title="What is Power BI?">Power BI</a> that they use to track the performance of the ASP.NET Core framework over time using dozens of benchmarks for
<a href=https://github.com/aspnet/Benchmarks title="ASP.NET Core Benchmarks on GitHub">ASP.NET Core</a> and the <a href=https://github.com/dotnet/performance title="The dotnet/performance repository on GitHub">.NET Runtime</a> that the product engineers can use to test
the impact of changes they make, and are run on a regular basis to identify regressions. You can read more about their
<a href=https://github.com/dotnet/aspnetcore/blob/main/docs/Benchmarks.md title="ASP.NET Core Benchmarks on GitHub">benchmarks</a> in GitHub.</p><p>As great as that would be, we&rsquo;re not all the likes of Microsoft, especially in the open source world. I don&rsquo;t know about you, but
I certainly don&rsquo;t have the budget to maintain a dedicated performance lab, physical or virtual, and a data warehouse to run on top
of it. How can we as open source software developers leverage the free tools available to us today to achieve something similar in
spirit to an Enterprise-level solution that still gives us value?</p><h2 id=prior-art-and-inspiration>Prior Art and Inspiration</h2><p>I&rsquo;m a big fan of <a href=https://github.com/features/actions title="GitHub Actions">GitHub Actions</a>, and use it for all of my own software projects to build and deploy my software,
as well to automate other tasks like <a href="https://www.youtube.com/live/pOeT1otTi4M?si=9OEq-rm_DTopVNd1&amp;t=172" title="On .NET Live - Effortless .NET updates with GitHub Actions">applying monthly .NET SDK updates</a> or housekeeping tasks like
<a href=https://github.com/martincostello/github-automation/blob/adf8d8b14b6b8ac7be8ca8f30614ac4dfb137642/.github/workflows/acr-housekeeping.yml title="A GitHub Actions workflow to clean up ACR images">clearing out old Azure Container Registry images</a>. GitHub Actions also comes with a generous free tier for public
repositories - at the time of writing you get unlimited minutes for running GitHub Actions workflows, capped at
<a href=https://docs.github.com/en/actions/administering-github-actions/usage-limits-billing-and-administration title="GitHub Actions usage limits, billing and administration">20 concurrent jobs</a> for Linux and Windows runners (macOS is less generous, at 5).</p><p>GitHub Actions isn&rsquo;t ever going to be a like-for-like replacement for dedicated performance machines, especially on the free tier
rather than with custom dedicated runners, but it&rsquo;s a great alternative. We can&rsquo;t rely on these runners to give us accurate <em>absolute</em>
benchmark results (i.e. how fast can my code possibly ever go), but we can use them to give us good <em>relative</em> benchmark results to
produce trends over time. There will still be an element of noise in the results due to the shared nature of the runners because
we have no control over the underlying hardware they run on, so they may change unexpectedly over time as the service is upgraded,
but that&rsquo;s a trade-off that can be balanced against the usefulness of such an architecture for a <em>&ldquo;budget performance lab&rdquo;</em>.</p><p>Given that, my first thought was that someone must have already written a GitHub Action to run benchmarks and collect the data for
them. Indeed, that was the case and the action I found that ended up being a major source of inspiration for my own setup was the
<a href=https://github.com/benchmark-action/github-action-benchmark title="The github-action-benchmark repository on GitHub">benchmark-action/github-action-benchmark</a> action.</p><p>The action supports 10 existing performance testing tools, including BenchmarkDotNet for .NET, other tools for Go, Java and Python,
as well as custom tools. The action ingests the output of these tools, summarises the results into a JSON document, and then
pushes the results into a GitHub repository. It also commits static assets like HTML, CSS and JavaScript files to the repository
alongside the results so that you can view the results in a web browser. The static pages include charts generated using <a href=https://www.chartjs.org title="Chart.js website">Chart.js</a>
so that you can view trends in the data over time and spot regressions. The action can also be configured to comment on pull requests
or commits if it determines that a regression has occurred in the benchmark data, removing some of the burden of needing to watch
for changes by eye.</p><p>By setting up a <a href=https://pages.github.com/ title="GitHub Pages">GitHub Pages</a> site to serve a website for the content of the repository, you can use the static HTML
files to visualise the results of the benchmarks in a browser. GitHub Pages is free to use, so using a public GitHub repository (free)
to store the data in conjunction with GitHub Pages to view the results (free) and GitHub Actions to run BenchmarkDotNet to generate the
results (free), you can see how we&rsquo;ve got all the pieces in place to host a continuous benchmarking solution without needing a budget for
any hardware, infrastructure or hosting.</p><h2 id=the-solution>The Solution</h2><p>OK, so if there&rsquo;s already an action do to all of this, why did I go and write my own version of it? While the existing action is great,
because it&rsquo;s focused on multiple different tools, there&rsquo;s an element of <em>least common denominator</em> to the features it has. The key feature
that it lacked for BenchmarkDotNet was the ability to visualise memory allocations in the charts in addition to the time/duration for
the benchmarks. There were also a number of minor other things I wanted to be able to do that the existing action didn&rsquo;t support out-of-the-box,
like customing Git commit details.</p><p>While the UI it provides by default is functional, and it&rsquo;s possible to create your own custom UI to visualise the data, the JavaScript to
generate the dashboards hasn&rsquo;t really been designed with testability and extensibility in mind (in my opinion). As I started to customise
the provided code over a week or so to meet my needs, I found I was often breaking it with unintentional regressions, and it was difficult
to test in the form it&rsquo;s provided in by default.</p><p>With that in mind, I decided I would create my own fork-in-spirit of the original action, but with a focus on BenchmarkDotNet. This would
allow me to customise the UI to my needs, and to make it more testable and extensible in the future. Also, a new side-project is always a
fun excuse to learn some new technology!</p><h3 id=storing-the-data>Storing the Data</h3><p>The first part of the solution, the data storage, is the easiest part. For this, all I needed to do was create a new public GitHub repository
(<a href=https://github.com/martincostello/benchmarks title="Benchmarks data repository on GitHub">martincostello/benchmarks</a>, how imaginative). For the design, the repository uses its branches to represent branches in
the source repository, with the data for each specific repository stored in a directory named after the repository. The data is then stored
in JSON files checked into the repository, providing a history of the benchmark data over time that can be tracked using standard Git tools.</p><p>Using a dedicated repository for the data has a number of benefits:</p><ul><li>All the data is stored in one repository, making it easy to access and query (and potentially migrate in the future if I need to change the data format);</li><li>The benchmark results do not affect the Git history of the source repository;</li><li>The dashboard can be deployed and versioned independently of the data - otherwise there&rsquo;d be a lot of churn in the repository as the data is pushed.</li></ul><p>The main trade-off here, compared to storing data in the source repository, is that each repository generating benchmark results needs to
have a GitHub access token configured that has write access to the data repository. This is just a minor inconvenience in terms of needing
to add it to the neccessary repositories, rather than security concern. There&rsquo;s nothing stored in the data repository other than the data
and GitHub files (README etc.).</p><h3 id=generating-the-benchmarks>Generating the Benchmarks</h3><p>For the second part of the solution, I created a new custom GitHub Action based on the existing action: <a href=https://github.com/martincostello/benchmarkdotnet-results-publisher title="The benchmarkdotnet-results-publisher repository on GitHub">martincostello/benchmarkdotnet-results-publisher</a></p><p>The action is written in TypeScript, so it runs as a native JavaScript action in GitHub Actions workflows, rather than needing any
additional software to be installed on a GitHub Actions runner.</p><p>Some of the improvements I made for my version of the action include:</p><ul><li>Add data points for memory allocations when present to the Benchmark.NET results&rsquo; JSON;</li><li>Support for customising the Git commit message and author details;</li><li>Pushing the data to the repository using the GitHub API to avoid the need to clone the data repository;</li><li>Pushing the data as valid JSON, rather than as a JavaScript object literal assigned to a <code>window</code> global variable.</li></ul><p>With the action published, the next step is to use it to generate the benchmark results from the source repositories.</p><p>I won&rsquo;t get into the specifics of writing the actual benchmarks using BenchmarkDotNet, but the key part is a GitHub Actions workflow
(<a href=https://github.com/martincostello/api/blob/main/.github/workflows/benchmark-ci.yml title="GitHub Actions workflow to run the benchmarks">example</a>) that runs the benchmarks using a GitHub-hosted Linux runner. At the time of writing, these use Ubuntu
22.04 using x64 processors and have 1 CPU with 4 logical cores. The workflow then uses the action once the benchmarks have been run
to publish the results to the <a href=https://github.com/martincostello/benchmarks title="Benchmarks data repository on GitHub">benchmarks repository</a>. The workflow runs for all pushes to a number of branches in the
repository, as well as being able to be run on-demand if needed.</p><p>I&rsquo;ve chosen not to run the benchmarks on every pull request for a few reasons:</p><ul><li>Pull requests from forks and from Dependabot do not have access to secrets - this means the data cannot be pushed to the other repository;</li><li>I don&rsquo;t want to tie-up a lot of my GitHub Actions capacity running the benchmarks for all PRs given that most pull requests are unlikely
to change the performance characteristics of the code;</li><li>If a regression is detected post-merge (<a href=https://github.com/martincostello/project-euler/pull/335#issuecomment-2302688319 title="Example of a comment on a pull request for a regression">like this</a>), I can easily investigate the cause after-the-fact and either fix-forward or revert the change.</li></ul><p>The only requirement over basic BenchmarkDotNet usage is that the benchmarks need to be run with the <code>--exporters json</code> option to
generate the benchmark results in JSON format. This is for the action to use to generate the summarised data for the dashboard.</p><h3 id=visualising-the-data>Visualising the Data</h3><p>The final piece of the puzzle is <a href=https://benchmarks.martincostello.com/ title="Benchmarks dashboard deployed to GitHub Pages">the dashboard to visualise the data</a>. I&rsquo;ve been looking for a good excuse to try
writing something using <a href=https://learn.microsoft.com/aspnet/core/blazor/ title="ASP.NET Core Blazor">Blazor</a> for a while, but I&rsquo;ve never had a good reason to do so that would have otherwise needed a
re-architecture of an existing web application of mine. This seemed like a great opportunity to give it a try and learn something new.</p><p>As the dashboard is hosted in a GitHub Pages site, there&rsquo;s no back-end to the application, so a Blazor WebAssembly (WASM) application
is the only avenue open to developing a Blazor application in this context.</p><p>I wouldn&rsquo;t consider myself a web developer (centering <code>div</code>s is always hard, somehow), but I found Blazor to basically be <em>&ldquo;React with C#&rdquo;</em>,
so given my comfort with C# and .NET development it was relatively easy to pick up once I got my head around a few new concepts
(the render cycle, etc.). The difference between the original HTML with embedded JavaScript and my new Blazor version is night and day.</p><p>I was also able to use <a href=https://github.com/dotnet/aspire title="The .NET Aspire repository on GitHub">.NET Aspire</a> as a good source of inspiration and practices for writing Blazor applications as the
Aspire Dashboard is itself a Blazor application (albeit not Blazor WASM). It was also the source of inspiration I used for moving from
Chart.js to <a href=https://plotly.com/javascript/ title="Plotly JavaScript Open Source Graphing Library">Plotly</a> for the charts in the dashboard so that I could add error bars to the data points from the benchmarks.</p><p>It was also an opportunity to look into <a href=https://bunit.dev/ title="bUnit: a testing library for Blazor components">bUnit</a> for testing the dashboard. I won&rsquo;t go on a tangent about bUnit, other than to say
I was really impressed with how it plugged into the existing .NET test ecosystem I&rsquo;m familiar with using <a href=https://xunit.net/ title=xUnit.net>xunit</a>. It was really easy
for me to add unit tests for the components and pages and get good coverage of the codebase (<a href=https://app.codecov.io/gh/martincostello/benchmarks-dashboard title="Code coverage for the benchmarks dashboard">80%+</a>) with existing tools like
<a href=https://github.com/coverlet-coverage/coverlet title="The Coverlet repository on GitHub">coverlet</a> and <a href=https://github.com/danielpalme/ReportGenerator title="The ReportGenerator repository on GitHub">ReportGenerator</a> to publish to <a href=https://about.codecov.io/ title="Codecov website">codecov.io</a>.</p><p>I was able to signficantly extend the original kernel of the dashboard idea from the github-action-benchmark action to include a number
of additional features that I wanted to be able to use. These included:</p><ul><li>Viewing all data from a single HTML page, not matter the repository or branch;</li><li>Being able to load the data using the GitHub API to support storing the data in a different repository;</li><li>Support for GitHub Enterprise Server or internal/private repositories (we can build and deploy copies of the dashboard onto my
employer&rsquo;s GitHub Enterprise Server instance for teams to use internally);</li><li>GitHub authentication using <a href=https://docs.github.com/apps/oauth-apps/building-oauth-apps/authorizing-oauth-apps#device-flow title="GitHub Device Flow documentation">device flow</a> to increase the rate limits for the GitHub API and support the above;</li><li>Deep-linking to specific repositories/branches/charts;</li><li>Downloading the charts as images for use elsewhere (like in blog posts or GitHub issues).</li></ul><p>You can find the source code for the dashboard in the <a href=https://github.com/martincostello/benchmarks-dashboard title="Benchmarks dashboard repository on GitHub">martincostello/benchmarks-dashboard</a> repository.
If you&rsquo;d like to host your own version, you can either fork it and modify it to your needs and deploy from there, or you could use the
repository via a <a href=https://git-scm.com/book/en/v2/Git-Tools-Submodules title="Git Tools - Submodules">Git submodule</a> in your own repository to host the dashboard in a subdirectory of your repository and
then customise the build process and change the configuration etc. before you deploy it. The submodule approach is what I&rsquo;ve used to
deploy an orange-themed version of the dashboard for use in GitHub Enterprise Server at my employer for some internal repositories.</p><h4 id=the-no-cost-exception>The No-Cost Exception</h4><p>The device flow support is the one exception to the &ldquo;no cost&rdquo; rule for the solution. As a client-side application with no back-end, the
normal GitHub OAuth flow cannot be used to authenticate a user to obtain an access token for the GitHub API as it would expose the client
secret to the browser. The <a href=https://docs.github.com/apps/oauth-apps/building-oauth-apps/authorizing-oauth-apps#device-flow title="GitHub Device Flow documentation">device flow</a> is a way to authenticate the user without needing a secret, but it does not
support CORS, so it&rsquo;s not possible to use it directly from a browser. To work around this, I added an endpoint to an existing API of mine
to proxy the device flow requests to GitHub with CORS support and then return the access token to the client.</p><p>This doesn&rsquo;t cost me anything <em>extra</em> as I already had a running piece of unrelated infrastructure that I could use for this purpose. If you
wanted to run this solution yourself with GitHub Enterprise Server, or private repositories, you would similarly need to deploy (or extend)
some infrastructure to proxy the device flow.</p><p>Similarly, I added a custom domain to the GitHub Pages site, but this was again a cost I already had for my domain and DNS, so wasn&rsquo;t an
<em>additional</em> cost. It&rsquo;s still possible to use the default GitHub Pages domain to host the site, you just don&rsquo;t get the custom/vanity URL
to serve it over.</p><blockquote><p>⚠️ If you need to use device flow with non-public repositories hosted in GitHub.com, you should do so over a custom domain so that you
can restrict the allowed hosts for CORS to your domain, as otherwise you would need to allow it for the entire GitHub Pages domain, or
otherwise restrict it somehow (e.g. by referrer or IP address).</p></blockquote><h3 id=the-end-result>The End Result</h3><p>With all the pieces in place, at a high-level the solution looks something like this:</p><p><img class="img-fluid mx-auto d-block" src=https://cdn.martincostello.com/blog_benchmarks-workflow.png alt="A sequence diagram showing how the application, data and dashboard repositories interact to render charts" title="A sequence diagram showing how the application, data and dashboard repositories interact to render charts"></p><p>Which for the end-user (i.e. me) gives a nice interactive dashboard to visualise the results like this:</p><p><img class="img-fluid mx-auto d-block" src=https://cdn.martincostello.com/blog_benchmarks-dashboard.png alt="A screenshot of the dashboard website showing two charts of time and memory consumption for a branch of a GitHub repository" title="A screenshot of the dashboard website showing two charts of time and memory consumption for a branch of a GitHub repository"></p><p>I&rsquo;ve set up a demo repository (<a href=https://github.com/martincostello/benchmarks-demo title="Benchmarks demo repository on GitHub">martincostello/benchmarks-demo</a>) that you can use as an inspiration for setting
up some Benchmark.NET benchmarks and then using a GitHub Actions workflow to run them and publish them to another repository.</p><h2 id=concrete-results>Concrete Results</h2><p>So with this solution in place, what have I been able to achieve with it so far?</p><p>First, the dashboard was incredibly useful to track the fixes for a number of performance improvements in the new ASP.NET Core OpenAPI
library. These are covered in more detail in <a href=https://blog.martincostello.com/whats-new-for-openapi-with-dotnet-9/ title="What's New for OpenAPI with .NET 9">my previous blog post</a>, but the dashboard was invaluable in tracking the
effect of the changes on the performance of the library over time as changes were made, particularly when ASP.NET Core 9 Release Candidate 1
was released.</p><p>The second concrete outcome from using the dashboard was the discovery of a performance regression in the .NET Runtime in .NET 9.</p><p>With the release of .NET 9 RC1 on the 10th of September 2024, I updated a number of my own applications to use the new version of the runtime
as RC1 is the first preview of .NET 9 with &ldquo;go-live&rdquo; support. After updating a number of applications and deploying them to my &ldquo;production&rdquo;
environments, I took a look at the dashboard to review any changes in the performance of the applications.</p><p>I expected a good number of the benchmarks to show that the time taken for the benchmarks had reduced and/or used less memory. This was the
case for the majority of the benchmarks, but there was one benchmark that bucked the trend and went in the wrong direction.</p><p>Going back to the chart shown at the top of this blog post, you can see that the red line denoting memory usage has a noticeable,
and consistent, uptick a few commits ago:</p><p><img class="img-fluid mx-auto d-block" src=https://cdn.martincostello.com/blog_benchmarks-regression.png alt="A chart showing a time series for performance and memory usage with an increase in memory usage in the most recent data points" title="A chart showing a time series for performance and memory usage with an increase in memory usage in the most recent data points"></p><p>If we hover over the first data point in the uptick, we can see that the change is from the upgrade from .NET 8 to .NET 9 RC1:</p><p><img class="img-fluid mx-auto d-block" src=https://cdn.martincostello.com/blog_benchmarks-regression-tooltip.png alt="The above chart with a tooltip showing the Git commit associated with the increase in memory usage" title="The above chart with a tooltip showing the Git commit associated with the increase in memory usage"></p><p>I hadn&rsquo;t spotted this regression previously as the benchmark data is something I&rsquo;d started collecting relatively recently, and the trends
didn&rsquo;t go back far enough to show the regression at the time it was made through my testing of the .NET 9 pre-releases. It was only when
I merged the upgrade to <code>main</code> and the data I&rsquo;d started collecting in that branch for .NET 8 was the difference apparent.</p><p>The regression also escaped the regression comment functionality of the GitHub Action. The memory used compared to the previous commit was
~106% - this is lower than the default threshold of 200% (i.e. double, carried through from <a href=https://github.com/benchmark-action/github-action-benchmark title="The github-action-benchmark repository on GitHub">github-action-benchmark</a>)
to avoid noisy false positives from variance in the performance of the GitHub Actions runners. When I&rsquo;ve been running these benchmarks
for a bit longer, I might revisit this threshold to see if it can be lowered (either by changing the config, or maybe the default itself)
to avoid missing such regressions in the future. In this case, it was manual review that spotted it, rather than anything automated.</p><p>The <a href=https://github.com/martincostello/api/blob/28fc4e2a9267e98303ff896e5e3a1da292201d2b/tests/API.Benchmarks/ApiBenchmarks.cs#L42-L44 title="The benchmark that regressed">specific benchmark</a> calls <a href=https://github.com/martincostello/api/blob/28fc4e2a9267e98303ff896e5e3a1da292201d2b/src/API/ApiModule.cs#L85-L114 title="The endpoint that regressed">an endpoint</a> that as I use as the health endpoint in a number of
my applications for containers deployed to Azure App Service. The endpoint uses <code>JsonObject</code> to return a JSON payload that contains a number
of useful properties about the application, such as the Git commit it was built from, the version of .NET its running, etc. This isn&rsquo;t an area
I would have expected to see a regression, but also isn&rsquo;t on a critical path, so wouldn&rsquo;t have been particularly noticeable in usage of the
applications themselves. It also turned out not to be an anomaly, as the same endpoint is present in several of my applications copy-pasted,
and each one showed the same regression.</p><p>I figured it would be worth raising the issue with the .NET team, so I created a more pared-down version of the benchmark. The original benchmark
is an &ldquo;end-to-end&rdquo; benchmark that calls the endpoint over HTTP, so I extracted the body of the endpoint into a separate method and then benchmarked
it in isolation. By itself, the same code showed the same regression, but without being compensated for by improvements elsewhere in the .NET
9 runtime and ASP.NET Core 9, the regression was relatively significant. Compared to .NET 8, the memory usage had increased by 70% and the time
taken to run the benchmark had increased by 90%. Ouch.</p><p>I raised the issue with the .NET team, and they were able to identify the cause of the regression as part of
<a href=https://github.com/dotnet/core/blob/main/release-notes/9.0/preview/preview6/libraries.md#ordering-jsonobject-properties title="Ordering JsonObject properties">adding suport for explicit ordering of the properties of <code>JsonObject</code></a>: <a href=https://github.com/dotnet/runtime/issues/107869 title="Performance regression with JsonObject creation by +70%">dotnet/runtime#107869</a>.
The issue was fixed just three days later, and will be included in release candidate 2 of .NET 9 in October. The team also added new benchmarks
to their existing suite to ensure that such a regression in this area doesn&rsquo;t slip by in the future.</p><p>I think both these examples of otherwise unnoticed issues demonstrate the usefulness of having a continuous benchmarking solution in place!</p><h2 id=summary>Summary</h2><p>In this post I&rsquo;ve covered how I set up a continuous benchmarking solution using GitHub Actions, GitHub Pages and Blazor to run and visualise
the results of BenchmarkDotNet benchmarks without needing to spend any money on hardware, software or infrastructure. The solution is good
enough to provide a consistent relative view of the performance of the software I maintain over time, and to spot any regressions in their performance.</p><p>I&rsquo;m looking forward to see what changes, and any issues, this setup might reveal in 2025 and beyond once .NET 10 development kicks off.</p><p>If you&rsquo;d like to run your own copy of this solution, or if you have suggestions about how to improve or extend it, feel free to open an issue
in either the <a href=https://github.com/martincostello/benchmarkdotnet-results-publisher title="The benchmarkdotnet-results-publisher repository on GitHub">action</a> or <a href=https://github.com/martincostello/benchmarks-dashboard title="Benchmarks dashboard repository on GitHub">dashboard</a> repositories. I&rsquo;d also be curious to hear about any other issues
you might find that you wouldn&rsquo;t have otherwise noticed if you adopt this approach for your own code projects.</p><p>I hope you&rsquo;ve found this post interesting and its given you some inspiration to add a similar capability to your own workflows. 💡</p><hr><p><div class=row><div class=col-lg-6><a href="https://bsky.app/intent/compose?text=Continuous+Benchmarks+on+a+Budget+by+%40martincostello.com+-+https%3A%2F%2Fblog.martincostello.com%2Fcontinuous-benchmarks-on-a-budget%2F" target=_blank rel=noopener class="btn btn-info btn-sm" title="Share on Bluesky">Share on Bluesky
<span class="fa-brands fa-bluesky" aria-hidden=true></span></a></div></div></p><hr><footer><p><div class=row><div class="d-none d-md-block col">&copy; Martin Costello 2014-2025 |
Built from <a href=https://github.com/martincostello/blog/commit/main rel=noopener title="View commit main on GitHub">main</a> on <a href=https://github.com/martincostello/blog/tree/main rel=noopener title="View branch main on GitHub">main</a></div><div class=d-md-none><div class=col>&copy; Martin Costello 2014-2025</div></div></div></p></footer></main><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/bootswatch/5.3.7/flatly/bootstrap.min.css integrity="sha512-O+EA0Agf5+pB8u7CtnIAYq/BKyFPMT8c0DFjmqLyfIJJ9Fm8GBohV/0H0TFaZ96+jieN8zUVY4IkSBso9z6hpg==" crossorigin=anonymous referrerpolicy=no-referrer async><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer async><link rel=stylesheet href=/styles/site.css><script src=https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.3.7/js/bootstrap.bundle.min.js integrity="sha512-Tc0i+vRogmX4NN7tuLbQfBxa8JkfUSAxSFVzmU31nVdHyiHElPPy2cWfFacmCJKw0VqovrzKhdd2TSTMdAxp2g==" crossorigin=anonymous referrerpolicy=no-referrer></script><script src="https://www.googletagmanager.com/gtag/js?id=G-XJFV74HRL6" async></script><script>window.hugoSiteParams={render_analytics:!0,analytics_id:"G-XJFV74HRL6"}</script><script src=/scripts/site.js defer></script></body></html>